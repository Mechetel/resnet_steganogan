{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qYnJJYUxbdua"
   },
   "source": [
    "# SteganoGAN in Keras\n",
    "This notebook contains code attempting to reimplement SteganoGAN in Keras, for the purpose of better understanding (and scrutinizing) it.\n",
    "\n",
    "*Based on https://github.com/DAI-Lab/SteganoGAN/tree/master/steganogan*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OTRQl5_KUxUA"
   },
   "source": [
    "### Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QbnEM8Oubduh"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-02 23:40:09.949467: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"KERAS_BACKEND\"] = \"tensorflow\"\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.losses import BinaryCrossentropy, MeanSquaredError\n",
    "from tensorflow.keras.callbacks import CSVLogger, ModelCheckpoint, EarlyStopping\n",
    "from callbacks import SaveImages\n",
    "\n",
    "from models import (\n",
    "  steganogan_encoder_residual_model,\n",
    "  steganogan_decoder_basic_model,\n",
    "  steganogan_critic_model\n",
    ")\n",
    "\n",
    "from dataset_utils import normalize_img, create_message_dataset\n",
    "from keras_steganogan import KerasSteganoGAN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Image dimensions\n",
    "\n",
    "MESSAGE_DEPTH = 6\n",
    "BATCH_SIZE = 4\n",
    "IMAGE_HEIGHT = 128\n",
    "IMAGE_WIDTH = 128\n",
    "IMAGE_CHANNELS = 3\n",
    "IMAGE_SHAPE = (IMAGE_HEIGHT, IMAGE_WIDTH, IMAGE_CHANNELS)\n",
    "\n",
    "MODEL_PATH = 'steganoGAN_residual.keras'\n",
    "LOGS_PATH = 'steganoGAN_residual.csv'\n",
    "CALLBACK_IMAGES_PATH = 'images/callback'\n",
    "CALLBACK_IMAGES_OUTPUT_PATH = 'epoch_images'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build model for future train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = steganogan_encoder_residual_model(MESSAGE_DEPTH)\n",
    "decoder = steganogan_decoder_basic_model(MESSAGE_DEPTH)\n",
    "critic = steganogan_critic_model()\n",
    "\n",
    "steganoGAN = KerasSteganoGAN(\n",
    "  encoder=encoder,\n",
    "  decoder=decoder,\n",
    "  critic=critic,\n",
    "  data_depth=MESSAGE_DEPTH\n",
    ")\n",
    "\n",
    "steganoGAN.build([(1, IMAGE_HEIGHT, IMAGE_WIDTH, IMAGE_CHANNELS), (1, IMAGE_HEIGHT, IMAGE_WIDTH, MESSAGE_DEPTH)])\n",
    "\n",
    "if MODEL_PATH is not None and os.path.exists(MODEL_PATH):\n",
    "  steganoGAN.load_weights(MODEL_PATH)\n",
    "  \n",
    "steganoGAN.compile(\n",
    "  encoder_optimizer  = Adam(learning_rate=1e-4, beta_1=0.5),\n",
    "  decoder_optimizer  = Adam(learning_rate=1e-4, beta_1=0.5),\n",
    "  critic_optimizer   = Adam(learning_rate=1e-4, beta_1=0.5),\n",
    "  similarity_loss_fn = MeanSquaredError(),\n",
    "  decoder_loss_fn    = BinaryCrossentropy(from_logits=False)\n",
    ")\n",
    "\n",
    "# steganoGAN.models_summary()\n",
    "# steganoGAN.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download div2k dataset and complete it with random message dataset of {0, 1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 800 files.\n",
      "Found 100 files.\n"
     ]
    }
   ],
   "source": [
    "train_dir = '/Users/dmitryhoma/Projects/phd_dissertation/state_2/SteganoGAN/research/data/div2k/train'\n",
    "val_dir = '/Users/dmitryhoma/Projects/phd_dissertation/state_2/SteganoGAN/research/data/div2k/val'\n",
    "\n",
    "train_image_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "  train_dir,\n",
    "  label_mode=None,\n",
    "  color_mode='rgb',\n",
    "  batch_size=BATCH_SIZE,\n",
    "  seed=123,\n",
    "  image_size=(IMAGE_HEIGHT, IMAGE_WIDTH),\n",
    "  shuffle=True\n",
    ")\n",
    "\n",
    "val_image_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "  val_dir,\n",
    "  label_mode=None,\n",
    "  color_mode='rgb',\n",
    "  batch_size=BATCH_SIZE,\n",
    "  seed=123,\n",
    "  image_size=(IMAGE_HEIGHT, IMAGE_WIDTH),\n",
    "  shuffle=True\n",
    ")\n",
    "\n",
    "train_image_ds = train_image_ds.map(normalize_img, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "val_image_ds = val_image_ds.map(normalize_img, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "\n",
    "train_message_ds = create_message_dataset(len(train_image_ds)*BATCH_SIZE, IMAGE_HEIGHT, IMAGE_WIDTH, MESSAGE_DEPTH).batch(BATCH_SIZE, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "val_message_ds = create_message_dataset(len(val_image_ds)*BATCH_SIZE, IMAGE_HEIGHT, IMAGE_WIDTH, MESSAGE_DEPTH).batch(BATCH_SIZE, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "\n",
    "train_ds = tf.data.Dataset.zip((train_image_ds, train_message_ds)).prefetch(buffer_size=tf.data.AUTOTUNE)\n",
    "val_ds = tf.data.Dataset.zip((val_image_ds, val_message_ds)).prefetch(buffer_size=tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m152s\u001b[0m 716ms/step - critic_loss: -0.0078 - decoder_accuracy: 0.7602 - decoder_loss: 0.4796 - encoder_decoder_total_loss: 0.5312 - psnr: 14.8808 - realism_loss: 0.0179 - rs_bpp: 3.1229 - similarity_loss: 0.0336 - ssim: 0.5345 - val_critic_loss: -0.0113 - val_decoder_accuracy: 0.7686 - val_decoder_loss: 0.4644 - val_encoder_decoder_total_loss: 0.5325 - val_psnr: 14.3393 - val_realism_loss: 0.0294 - val_rs_bpp: 3.2238 - val_similarity_loss: 0.0386 - val_ssim: 0.5218\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x1117f6990>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "steganoGAN.fit(train_ds, epochs=1, validation_data=val_ds, callbacks=[\n",
    "  SaveImages(MESSAGE_DEPTH, IMAGE_SHAPE, CALLBACK_IMAGES_PATH, CALLBACK_IMAGES_OUTPUT_PATH),\n",
    "  ModelCheckpoint(MODEL_PATH, save_best_only=True, monitor='encoder_decoder_total_loss', mode='min'),\n",
    "  EarlyStopping(monitor='encoder_decoder_total_loss', mode='min', patience=10, min_delta=0.001),\n",
    "  CSVLogger(LOGS_PATH, append=True)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 185ms/step - critic_loss: -0.0107 - decoder_accuracy: 0.7708 - decoder_loss: 0.4609 - encoder_decoder_total_loss: 0.5317 - psnr: 14.4274 - realism_loss: 0.0330 - rs_bpp: 3.2494 - similarity_loss: 0.0378 - ssim: 0.5306\n",
      "encoder_decoder_total_loss: 0.5325661301612854\n",
      "critic_loss: -0.01129884459078312\n",
      "similarity_loss: 0.03869222104549408\n",
      "decoder_loss: 0.46444883942604065\n",
      "decoder_accuracy: 0.7687587141990662\n",
      "realism_loss: 0.029425162822008133\n",
      "psnr: 14.334359169006348\n",
      "ssim: 0.5213987827301025\n",
      "rs_bpp: 3.2251038551330566\n"
     ]
    }
   ],
   "source": [
    "evaluated_metrics = steganoGAN.evaluate(val_ds)\n",
    "\n",
    "metrics_names = [\n",
    "  'encoder_decoder_total_loss',\n",
    "  'critic_loss',\n",
    "  'similarity_loss',\n",
    "  'decoder_loss',\n",
    "  'decoder_accuracy',\n",
    "  'realism_loss',\n",
    "  'psnr',\n",
    "  'ssim',\n",
    "  'rs_bpp'\n",
    "]\n",
    "\n",
    "for key, value in zip(metrics_names, evaluated_metrics):\n",
    "  print(f'{key}: {value}')"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "steganogan_keras.ipynb",
   "provenance": [
    {
     "file_id": "https://github.com/jnickg/steganet/blob/main/steganogan_keras.ipynb",
     "timestamp": 1710610773710
    }
   ]
  },
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
